{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series forecasting using Radial basis function network ( regression)\n",
    "\n",
    "Data structure: \n",
    "- ID: Product Identifier\n",
    "- DATEOP: Date Operation (weekly)\n",
    "- NBRE: Sales/Demands count/quantity\n",
    "\n",
    "Goal n°1: one-month-ahead forecasting of each product\n",
    "\n",
    "Goal n°2: 4-month-ahead forecasting of each product.\n",
    "\n",
    "\"Product\" refers to an anonymous banking product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from matplotlib.pylab import rcParams\n",
    "from collections import defaultdict\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation,LSTM\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras import optimizers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=r'C:/Users/yesmi/Desktop/engineerinternship/btseries.txt'\n",
    "data= pd.read_csv(path,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 63 products\n",
    "data.ID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.ID=data.ID.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "for i in range (data.shape[0]):\n",
    "    data.DATEOP[i]=parser.parse(data.DATEOP[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#184 dates\n",
    "data.DATEOP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert a Time Series forecasting  to a Supervised Learning task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a multivariate time series data.\n",
    "We are going to use one stop sliding window approach to predict one-month-ahead of each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First transformation\n",
    "dat=data.pivot_table(index='DATEOP',\n",
    "                             columns='ID',\n",
    "                             values='NBRE',\n",
    "                             aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=pd.DataFrame(dat)\n",
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Products=dat.columns\n",
    "Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat=dat.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#second transformation\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\t\"\"\"\n",
    "\tFrame a time series as a supervised learning dataset.\n",
    "\tArguments:\n",
    "\t\tdata: Sequence of observations as a list or NumPy array.\n",
    "\t\tn_in: Number of lag observations as input (X).\n",
    "\t\tn_out: Number of observations as output (y).\n",
    "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
    "\tReturns:\n",
    "\t\tPandas DataFrame of series framed for supervised learning.\n",
    "\t\"\"\"\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dat=np.array(dat)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we will be using the 10 final dates ( for each product) to predict the value of the next month\n",
    "dt=series_to_supervised(dat,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Applying RBFN to predict the value of the first product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example to validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( dt.loc[:,'var1(t-10)':'var63(t-1)'] , dt.loc[:,'var1(t)':'var63(t)'] , test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=pd.DataFrame(y_train)\n",
    "y_test=pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.columns=Products\n",
    "y_test.columns=Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gaussian function\n",
    "\n",
    "def RBFunction(r, x,c ):\n",
    "    return( np.exp(- (distance.euclidean(x, c))**2/r**2))\n",
    "\n",
    "# Computing radial/spread\n",
    "\n",
    "def radial (x,c ):\n",
    "    r=[]\n",
    "    for i in range (c.shape[0]):\n",
    "        k=[]\n",
    "        for j in range(x.shape[0]) :\n",
    "            k.append(distance.euclidean(x.iloc[j,:], c[i])) \n",
    "        m=(sum(k)/len(k))\n",
    "        r.append(m)\n",
    "    return(r)\n",
    "\n",
    "# compute the centers using Kmeans\n",
    "\n",
    "def centers (data,n):\n",
    "    kmeans = KMeans(n_clusters=n)\n",
    "    a = kmeans.fit(data)\n",
    "    return(kmeans.cluster_centers_)     \n",
    "\n",
    "#Preparing the RBF network\n",
    "\n",
    "def RBF (centers,radials, X): \n",
    "    s=[[]for k in range (centers.shape[0])]\n",
    "    \n",
    "    for i in range (centers.shape[0]):\n",
    "        for j in range (X.shape[0]):\n",
    "            X=pd.DataFrame(X)\n",
    "            s[i] .append(RBFunction(radials[i] ,X.iloc[j,:],centers[i]))\n",
    "    s=pd.DataFrame(s)\n",
    "    return(s.transpose()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to evaluate the performance of the models\n",
    "def evaluate(y,pred):\n",
    "    #MAPE:Mean absolute percentage error\n",
    "    def MAPE(y,pred):\n",
    "        mapev=[]\n",
    "        aux1=y.reset_index(drop=True)\n",
    "        aux1=pd.Series(aux1)\n",
    "        aux2=pd.Series(pred)\n",
    "\n",
    "        for i in aux1.index:\n",
    "            if aux1[i]==0:\n",
    "                mapev.append(0)\n",
    "            else:\n",
    "                mapev.append(abs(aux1[i]-aux2[i])/aux1[i])\n",
    "\n",
    "        mape=(np.mean(mapev))*100\n",
    "        return(mape)\n",
    "\n",
    "#MAD:Mean absolute deviation\n",
    "    def MAD_MSD(y,pred):\n",
    "        madv=[]\n",
    "        mapev=[]\n",
    "        aux1=y.reset_index(drop=True)\n",
    "        aux1=pd.Series(aux1)\n",
    "        aux2=pd.Series(pred)\n",
    "        for i in aux1.index:\n",
    "            if aux1[i]==0:\n",
    "                mapev.append(0)\n",
    "            else:\n",
    "                mapev.append(abs(aux1[i]-aux2[i])/aux1[i])\n",
    "        for i in aux1.index:\n",
    "            if aux1[i]!=0:\n",
    "               madv.append(mapev[i]*aux1[i])\n",
    "            else:\n",
    "               madv.append(0)\n",
    "        mad=np.mean(madv)\n",
    "        #MSD:Mean squared deviation\n",
    "        msdv=np.square(madv)\n",
    "        msd=np.mean(msdv)\n",
    "        return(mad,msd)\n",
    "\n",
    "#SMAPE:Symmetric mean absolute percentage error\n",
    "    def SMAPE(y,pred):\n",
    "       smapev=[]\n",
    "       smape=0\n",
    "       aux1=y.reset_index(drop=True)\n",
    "       aux1=pd.Series(aux1)\n",
    "       aux2=pd.Series(pred)\n",
    "       for i in aux1.index:\n",
    "           if aux1[i]==0:\n",
    "              smapev.append(0)\n",
    "           else:\n",
    "               smapev.append(2*(abs(aux1[i]-aux2[i])/((abs(aux1[i])+abs(aux2[i])))))\n",
    "\n",
    "       smape = (np.mean(smapev))*100\n",
    "       return(smape)\n",
    "    MAPE=MAPE(y,pred)\n",
    "    MAD,MSD=MAD_MSD(y,pred)\n",
    "    SMAPE=SMAPE(y,pred)\n",
    "    nn=['MAPE','MAD','MSD','SMAPE']\n",
    "    kk=[MAPE,MAD,MSD,SMAPE]\n",
    "    eva=pd.DataFrame([nn,kk])\n",
    "    return(eva)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#neural network initialization\n",
    "# Hyperparameter: number of centers/units of the hidden layer nc\n",
    "nc=80\n",
    "#Train\n",
    "c=centers(X_train , nc)\n",
    "r=radial(X_train,c)\n",
    "inputs_train= pd.DataFrame(RBF(c,r,X_train))\n",
    "\n",
    "#Test\n",
    "inputs_t= pd.DataFrame(RBF(c,r,X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting with linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#linear model\n",
    "from sklearn import linear_model\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "mr=regr.fit(X_train, y_train.iloc[:,0])\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "var=explained_variance_score(y_test.iloc[:,0], y_pred) \n",
    "mae=mean_absolute_error(y_test.iloc[:,0], y_pred)\n",
    "mse=mean_squared_error(y_test.iloc[:,0], y_pred)\n",
    "rmse=np.sqrt(mse)\n",
    "r2=r2_score(y_test.iloc[:,0], y_pred )  \n",
    "metric=[var,mae,mse,rmse,r2]\n",
    "nn=['Explained variance','MAE','MSE','RMSE','R^2']\n",
    "performance=pd.DataFrame([nn,metric])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval1=evaluate( y_test.iloc[:,0],y_pred)\n",
    "eval1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sklearn package (MLPRegressor) to implement the second part of the RBFNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=MLPRegressor(activation='identity',alpha=0.05,learning_rate ='adaptive',verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=m.fit(inputs_train,y_train.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "out=m.predict(inputs_train)\n",
    "var=explained_variance_score(y_train.iloc[:,0], out) \n",
    "mae=mean_absolute_error(y_train.iloc[:,0], out)\n",
    "mse=mean_squared_error(y_train.iloc[:,0], out)\n",
    "rmse=np.sqrt(mse)\n",
    "r2=r2_score(y_train.iloc[:,0], out ) \n",
    "#r2a=1-((1-r2)* (1000-1) /(1000-1-5)) \n",
    "nn=['Explained variance','MAE','MSE','RMSE','R^2']\n",
    "metric=[var,mae,mse,rmse,r2]\n",
    "performance=pd.DataFrame([nn,metric])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_train.iloc[:,0], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "outt=m.predict(inputs_t)\n",
    "var=explained_variance_score(y_test.iloc[:,0], outt) \n",
    "mae=mean_absolute_error(y_test.iloc[:,0], outt)\n",
    "mse=mean_squared_error(y_test.iloc[:,0], outt)\n",
    "rmse=np.sqrt(mse)\n",
    "r2=r2_score(y_test.iloc[:,0], outt) \n",
    "#r2a=1-((1-r2)* (1000-1) /(1000-1-5)) \n",
    "nn=['Explained variance','MAE','MSE','RMSE','R^2']\n",
    "metric=[var,mae,mse,rmse,r2]\n",
    "performance=pd.DataFrame([nn,metric])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_test.iloc[:,0], outt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Kears package to implement the second part of the RBFNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def baseline_model():\n",
    "    # create model\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=nc, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "#data preparation\n",
    "inputs_train_arr=np.array(inputs_train)\n",
    "inputs_t_arr=np.array(inputs_t)\n",
    "y_train_arr=np.array(y_train.iloc[:,0])\n",
    "y_t_arr=np.array(y_test.iloc[:,0])\n",
    "\n",
    "#train the model\n",
    "model.fit(inputs_train_arr,y_train_arr, epochs=3000, batch_size=20,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "out=model.predict(inputs_train_arr)\n",
    "var=explained_variance_score(y_train.iloc[:,0], out) \n",
    "mae=mean_absolute_error(y_train.iloc[:,0], out)\n",
    "mse=mean_squared_error(y_train.iloc[:,0], out)\n",
    "rmse=np.sqrt(mse)\n",
    "r2=r2_score(y_train.iloc[:,0], out ) \n",
    "nn=['Explained variance','MAE','MSE','RMSE','R^2']\n",
    "metric=[var,mae,mse,rmse,r2]\n",
    "performance=pd.DataFrame([nn,metric])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=np.array(out)\n",
    "out=np.squeeze(out)\n",
    "evaluate(y_train.iloc[:,0], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "outt=model.predict(inputs_t_arr)\n",
    "var=explained_variance_score(y_test.iloc[:,0], outt) \n",
    "mae=mean_absolute_error(y_test.iloc[:,0], outt)\n",
    "mse=mean_squared_error(y_test.iloc[:,0], outt)\n",
    "rmse=np.sqrt(mse)\n",
    "r2=r2_score(y_test.iloc[:,0], outt) \n",
    "nn=['Explained variance','MAE','MSE','RMSE','R^2']\n",
    "metric=[var,mae,mse,rmse,r2]\n",
    "performance=pd.DataFrame([nn,metric])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=np.array(outt)\n",
    "out=np.squeeze(out)\n",
    "evaluate(y_test.iloc[:,0], out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Applying RBFN to predict the value of all products for the next month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Products= the products' names \n",
    "#nc=number of centers\n",
    "#n_in= how much history\n",
    "def tspredict1(Products,data,n_in,nc):\n",
    "   dt=series_to_supervised(data,n_in,1)\n",
    "   y=pd.DataFrame( dt.loc[:,'var1(t)':])\n",
    "   X=dt.iloc[:,:(n_in*len(Products))]\n",
    "   c=centers(X,nc)\n",
    "   r=radial(X,c)\n",
    "   inputs= pd.DataFrame(RBF(c,r,X))\n",
    "   inputs__arr=np.array(inputs)\n",
    "   y__arr=np.array(y)\n",
    "   prediction=[]\n",
    "   performance=pd.DataFrame()\n",
    "   \n",
    "   #m=MLPRegressor(activation='identity',alpha=0.05,learning_rate ='adaptive',verbose=False)\n",
    " \n",
    "   for i in range(len(Products)):\n",
    "        #mod=m.fit(inputs,y.iloc[:,i])\n",
    "        model.fit(inputs__arr,y__arr[:,i], epochs=100, batch_size=20,verbose=1)\n",
    "        pred=model.predict(inputs__arr)\n",
    "        pred=np.squeeze(pred)\n",
    "        ev=evaluate(y.iloc[:,i],pred)\n",
    "        prediction.append(pred[len(pred)-1])\n",
    "        performance=performance.append(ev)\n",
    "   prediction=pd.DataFrame(prediction)\n",
    "   return(prediction,performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred,Performance=tspredict1(Products,dt,10,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred[pred<0]=0\n",
    "Products=pd.DataFrame(Products)\n",
    "Prediction=pd.concat([Products,pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-month prediction for all products\n",
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance for each product prediction\n",
    "Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
