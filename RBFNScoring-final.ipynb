{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the radial basis function network implementation ( using the hybrid approach/ clustering based) and applied to an imbalanced train and test data set for credit scoring after data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters to control in this code :\n",
    "\n",
    "nc= number of centers\n",
    "\n",
    "optimizer\n",
    "\n",
    "epochs\n",
    "\n",
    "batch size\n",
    "\n",
    "threshold\n",
    "\n",
    "dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Reshape\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "path=r'C:/Users/zZiZzou_Tech/Desktop/engineerinternship/datascoring-train.csv'\n",
    "train= pd.read_csv(path,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(train.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "path=r'C:/Users/zZiZzou_Tech/Desktop/engineerinternship/datascoring-test.csv'\n",
    "test = pd.read_csv(path,sep=',')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.drop(test.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.index = range(55087,83464)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.concat([train,test])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AGE=list()\n",
    "MONTH=list()\n",
    "for i in range (len(data.index)):\n",
    "    birth_date=str(data.NAISS[i])\n",
    "    credit_date=str(data.DATDBL[i])\n",
    "    AGE.append(int('20'+credit_date[(len(credit_date)-2):len(credit_date)])- int(birth_date[0:4]))\n",
    "    if len(credit_date)==5:\n",
    "       MONTH.append(int(credit_date[1:3]))\n",
    "    else:\n",
    "       MONTH.append(int(credit_date[2:4]))  \n",
    "del data['NAISS']\n",
    "del data['DATDBL']\n",
    "data.insert(1,'AGE',AGE)\n",
    "data.insert(2,'MONTH',MONTH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting data into categorial and non categorial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_categorial_features = ['NBENF',\n",
    "                          'SALR',\n",
    "                          'AGE',\n",
    "                          'RMBMNT',\n",
    "                          'CRDMNT',\n",
    "                          'NBCPTE',\n",
    "                          'BICCPENC',\n",
    "                          'BICRIENC',\n",
    "                          'NBDEB',\n",
    "                          'NBCRD',\n",
    "                          'SLDANN']\n",
    "\n",
    "categorial_features=['SEX',\n",
    "                    'AECO',\n",
    "                    'SCPRO',\n",
    "                    'PROF',\n",
    "                    'ETCV',\n",
    "                    'AGC',\n",
    "                    'MONTH']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling ( standard scaler) of the non categorial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_quanti=data.loc[:,non_categorial_features]\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "dataquanti_sc =scaler.fit_transform(data_quanti)\n",
    "\n",
    "\n",
    "dataquanti=pd.DataFrame(dataquanti_sc)\n",
    "dataquanti.columns= ['NBENF',\n",
    "                          'SALR',\n",
    "                          'AGE',\n",
    "                          'RMBMNT',\n",
    "                          'CRDMNT',\n",
    "                          'NBCPTE',\n",
    "                          'BICCPENC',\n",
    "                          'BICRIENC',\n",
    "                          'NBDEB',\n",
    "                          'NBCRD',\n",
    "                          'SLDANN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hot encoding for the categorial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_quali=data.loc[:,categorial_features]\n",
    "data_quali.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in list(data_quali):\n",
    "    data_quali[i] = data_quali[i].astype('category')\n",
    "dataquali=pd.get_dummies(data_quali, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataquali.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New data transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdata=pd.concat([data['Y'] ,dataquanti,dataquali],axis=1)\n",
    "newdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respliting train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=newdata[:len(train)]\n",
    "test=newdata[len(train):len(test)+len(train)]\n",
    "test=test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train.iloc[:,1:] \n",
    "y_train=train['Y']\n",
    "\n",
    "X_test = test.iloc[:,1:] \n",
    "y_test=test['Y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radial Basis Function Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gaussian function\n",
    "\n",
    "def RBFunction(r, x,c ):\n",
    "    return( np.exp(- (distance.euclidean(x, c))**2/r**2))\n",
    "\n",
    "# Computing radial/spread\n",
    "\n",
    "def radial (x,c ):\n",
    "    r=[]\n",
    "    for i in range (c.shape[0]):\n",
    "        k=[]\n",
    "        for j in range(x.shape[0]) :\n",
    "            k.append(distance.euclidean(x.iloc[j,:], c[i])) \n",
    "        m=(sum(k)/len(k))\n",
    "        r.append(m)\n",
    "    return(r)\n",
    "\n",
    "# compute the centers using Kmeans\n",
    "\n",
    "def centers (data,n):\n",
    "    kmeans = KMeans(n_clusters=n).fit(data )\n",
    "    return(kmeans.cluster_centers_)     \n",
    "\n",
    "#Preparing the RBF network\n",
    "\n",
    "def RBF (centers,radials, X): \n",
    "    s=[[]for k in range (centers.shape[0])]\n",
    "    \n",
    "    for i in range (centers.shape[0]):\n",
    "        for j in range (X.shape[0]):\n",
    "            X=pd.DataFrame(X)\n",
    "            s[i] .append(RBFunction(radials[i] ,X.iloc[j,:],centers[i]))\n",
    "    s=pd.DataFrame(s)\n",
    "    return(s.transpose()) \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step: applying clustering  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameter: number of centers/units of the hidden layer\n",
    "nc= 40000\n",
    "#Train\n",
    "c=centers(X_train , nc)\n",
    "r=radial(X_train,c)\n",
    "inputs_train= pd.DataFrame(RBF(c,r,X_train))\n",
    "\n",
    "\n",
    "#Test\n",
    "inputs_t= pd.DataFrame(RBF(c,r,X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sklearn package (MLPClassifier) to implement the second part of the RBFNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1=MLPClassifier(activation='logistic' ,solver='lbfgs',momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod1=m1.fit(inputs_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing the performance of the model using different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "out=m1.predict(inputs_train)\n",
    "#accuracy \n",
    "acc1=m1.score(inputs_train,y_train)\n",
    "#roc auc\n",
    "auc1=roc_auc_score(y_train,out)\n",
    "#precision\n",
    "prec1=precision_score(y_train ,out)\n",
    "#precision-recall auc\n",
    "pr1=average_precision_score(y_train ,out)\n",
    "#Recall\n",
    "rec1=recall_score(y_train, out)\n",
    "#F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f11=f1_score(y_train ,out)\n",
    "m=[acc1,auc1,pr1,prec1,rec1,f11]\n",
    "n=['Accuracy','ROC-auc','PR-auc','Precision','Recall','F1-score']\n",
    "performance=pd.DataFrame([n,m])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "out=m1.predict(inputs_t)\n",
    "#accuracy \n",
    "acc1=m1.score(inputs_t,y_test)\n",
    "#roc auc\n",
    "auc1=roc_auc_score(y_test,out)\n",
    "#pr-auc \n",
    "pr1=average_precision_score(y_test ,out)\n",
    "#precision\n",
    "rec1=precision_score(y_test,out)\n",
    "#Recall\n",
    "rec1=recall_score(y_test, out)\n",
    "#F1 score\n",
    "f11=f1_score(y_test ,out)\n",
    "m=[acc1,auc1,pr1,prec1,rec1,f11]\n",
    "n=['Accuracy','ROC-auc','PR-auc','Precision','Recall','F1-score']\n",
    "performance=pd.DataFrame([n,m])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#roc curve:\n",
    "fpr,tpr,_=roc_curve(y_test, out)\n",
    "plt.plot(fpr,tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Precision recall curve:\n",
    "pr,rec,_=precision_recall_curve(y_test,probas_pred=out)\n",
    "plt.plot(rec,pr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Confusion matrix:\n",
    "cm=pd.DataFrame(confusion_matrix(y_test,out))\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using Kears package  to implement the second part of the RBFNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function used to modify threshold \n",
    "def out (v,s):\n",
    "    c= []\n",
    "    for i in range(v.shape[0]):\n",
    "        if output[i,1]>s:\n",
    "           c.append(1)\n",
    "        else:\n",
    "           c.append(0)\n",
    "    return(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cost sensitive classification\n",
    "class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_train_arr=np.array(inputs_train)\n",
    "inputs_t_arr=np.array(inputs_t)\n",
    "y_train_arr=np.array(y_train)\n",
    "y_t_arr=np.array(y_test)\n",
    "\n",
    "dimof_input = inputs_train_arr.shape[1]\n",
    "\n",
    "y_cat = np_utils.to_categorical(y_train_arr,2)\n",
    "dimof_output_cat=y_cat.shape[1]\n",
    "\n",
    "y_t_cat=np_utils.to_categorical(y_t_arr,2)\n",
    "y_t_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "\n",
    "batch_size = 100\n",
    "dropout = 0.2\n",
    "epochs = 3000\n",
    "verbose = 1\n",
    "threshold=0.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set model\n",
    "\n",
    "\n",
    "The different optimizers that can be used:\n",
    "optimizers=['sgd','adam','rmsprop','adagrad','adamax','nadam']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(dimof_input,dimof_output):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dimof_output, input_dim=dimof_input))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(dimof_output, init=keras.initializers.RandomNormal(mean=0.0, stddev=0.05), activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=build_model(dimof_input,dimof_output_cat)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(inputs_train_arr,y_cat, batch_size=batch_size,class_weight=class_weight, epochs=epochs,verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "output=model.predict(inputs_train_arr)\n",
    "output_t=out(output,threshold)\n",
    "#accuracy\n",
    "score, acc = model.evaluate(inputs_train_arr, y_cat)\n",
    "#roc auc\n",
    "auc1=roc_auc_score(y_train_arr ,output_t)\n",
    "#precision\n",
    "prec1=precision_score(y_train_arr ,output_t)\n",
    "#precision-recall auc\n",
    "pr1=average_precision_score(y_train_arr ,output_t)\n",
    "#Recall\n",
    "rec1=recall_score(y_train_arr, output_t)\n",
    "#F1 score\n",
    "f11=f1_score(y_train_arr ,output_t)\n",
    "m=[acc,auc1,pr1,prec1,rec1,f11]\n",
    "n=['Accuracy','ROC-auc','PR-auc','Precision','Recall','F1-score']\n",
    "performance=pd.DataFrame([n,m])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "output=model.predict(inputs_t_arr)\n",
    "output_t=out(output,threshold)\n",
    "#accuracy\n",
    "score, acc = model.evaluate(inputs_t_arr, y_t_cat)\n",
    "#roc auc\n",
    "auc1=roc_auc_score(y_t_arr ,output_t)\n",
    "#pr auc\n",
    "pr1=average_precision_score(y_t_arr ,output_t)\n",
    "#precision\n",
    "prec1=precision_score(y_t_arr ,output_t)\n",
    "#recall\n",
    "rec1=recall_score(y_t_arr, output_t)\n",
    "#f1score\n",
    "f11=f1_score(y_t_arr ,output_t)\n",
    "\n",
    "m=[acc,auc1,pr1,prec1,rec1,f11]\n",
    "n=['Accuracy','ROC-auc','PR-auc','Precision','Recall','F1-score']\n",
    "\n",
    "performance=pd.DataFrame([n,m])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#roc curve:\n",
    "fpr,tpr,_=roc_curve(y_test, output[:,1])\n",
    "plt.plot(fpr,tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Precision recall curve:\n",
    "pr,rec,_=precision_recall_curve(y_test , probas_pred=output[:,1])\n",
    "plt.plot(rec,pr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Confusion matrix:\n",
    "cm=pd.DataFrame(confusion_matrix(y_test,output_t))\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
